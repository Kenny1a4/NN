{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "70d20691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available: 0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "055f814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ab9d9599",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ğ—Ğ°Ğ²Ğ°Ğ½Ñ‚Ğ°Ğ¶ÑƒÑ”Ğ¼Ğ¾ Ğ³Ğ¾Ñ‚Ğ¾Ğ²Ğ¸Ğ¹ Ğ´Ğ°Ñ‚Ğ°ÑĞµÑ‚ IMDB\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "# ĞŸĞ°Ñ€Ğ°Ğ¼ĞµÑ‚Ñ€Ğ¸\n",
    "max_words = 30000   # Ğ±Ñ–Ğ»ÑŒÑˆĞµ ÑĞ»Ñ–Ğ² Ñƒ ÑĞ»Ğ¾Ğ²Ğ½Ğ¸ĞºÑƒ\n",
    "max_len = 300       # Ğ´Ğ¾Ğ²ÑˆÑ– Ñ‚ĞµĞºÑÑ‚Ğ¸\n",
    "embedding_dim = 256 # Ñ€Ğ¾Ğ·Ğ¼Ñ–Ñ€ embedding\n",
    "# lstm_units = 256    # Ğ±Ñ–Ğ»ÑŒÑˆĞµ Ğ½ĞµĞ¹Ñ€Ğ¾Ğ½Ñ–Ğ² Ñƒ LSTM\n",
    "\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.imdb.load_data(num_words=max_words)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "312a897d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞŸĞ°Ğ´Ğ´Ğ¸Ğ½Ğ³ (Ğ²Ğ¸Ñ€Ñ–Ğ²Ğ½ÑĞ²Ğ°Ğ½Ğ½Ñ Ğ´Ğ¾Ğ²Ğ¶Ğ¸Ğ½Ğ¸)\n",
    "x_train = keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
    "x_test = keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b8f82d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ĞœĞ¾Ğ´ĞµĞ»ÑŒ\n",
    "model = keras.Sequential([\n",
    "    layers.Embedding(max_words, 128, input_length=max_len),\n",
    "    layers.LSTM(64, dropout=0.3, recurrent_dropout=0.2),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "3a271015",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=3, restore_best_weights=True),\n",
    "    ModelCheckpoint(\"best_imdb_model.h5\", save_best_only=True)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "1e2cd2b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 202ms/step - accuracy: 0.6958 - loss: 0.5637"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 217ms/step - accuracy: 0.7419 - loss: 0.5229 - val_accuracy: 0.7454 - val_loss: 0.5180\n",
      "Epoch 2/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 210ms/step - accuracy: 0.8439 - loss: 0.3731"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 224ms/step - accuracy: 0.8531 - loss: 0.3543 - val_accuracy: 0.8314 - val_loss: 0.3844\n",
      "Epoch 3/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 213ms/step - accuracy: 0.9020 - loss: 0.2611"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 227ms/step - accuracy: 0.8947 - loss: 0.2699 - val_accuracy: 0.8436 - val_loss: 0.3802\n",
      "Epoch 4/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 231ms/step - accuracy: 0.9286 - loss: 0.1918 - val_accuracy: 0.8376 - val_loss: 0.4070\n",
      "Epoch 5/5\n",
      "\u001b[1m625/625\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 233ms/step - accuracy: 0.9111 - loss: 0.2303 - val_accuracy: 0.8390 - val_loss: 0.4236\n"
     ]
    }
   ],
   "source": [
    "# ĞĞ°Ğ²Ñ‡Ğ°Ğ½Ğ½Ñ\n",
    "history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=5,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    "    callbacks=callbacks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "f5b0e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m782/782\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 59ms/step - accuracy: 0.8336 - loss: 0.3974\n",
      "Test loss: 0.3974251449108124\n",
      "Test accuracy: 0.8335599899291992\n"
     ]
    }
   ],
   "source": [
    "# Ğ¢ĞµÑÑ‚ÑƒĞ²Ğ°Ğ½Ğ½Ñ\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f69f815f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Ğ”ĞµĞºĞ¾Ğ´ĞµÑ€ ÑĞ»Ñ–Ğ² (Ñ‰Ğ¾Ğ± Ğ¿ĞµÑ€ĞµÑ‚Ğ²Ğ¾Ñ€Ğ¸Ñ‚Ğ¸ Ñ‡Ğ¸ÑĞ»Ğ° Ğ² Ñ‚ĞµĞºÑÑ‚ Ñ– Ğ½Ğ°Ğ·Ğ°Ğ´) ---\n",
    "word_index = keras.datasets.imdb.get_word_index()\n",
    "index_word = {v+3: k for k, v in word_index.items()}\n",
    "index_word[0] = \"<PAD>\"\n",
    "index_word[1] = \"<START>\"\n",
    "index_word[2] = \"<UNK>\"\n",
    "index_word[3] = \"<UNUSED>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "4e5ab0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def predict_review(text):\n",
    "    # Ğ¢Ğ¾ĞºĞµĞ½Ñ–Ğ·Ğ°Ñ†Ñ–Ñ ÑĞ²Ğ¾Ñ—Ñ… ÑĞ»Ñ–Ğ² (IMDB ÑĞ»Ğ¾Ğ²Ğ½Ğ¸Ğº Ğ°Ğ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ¸Ğ¹!)\n",
    "    tokens = [word_index.get(word.lower(), 2) for word in text.split()]  # 2 = <UNK>\n",
    "    tokens = pad_sequences([tokens], maxlen=max_len)\n",
    "    prediction = model.predict(tokens)[0][0]\n",
    "    if prediction > 0.5:\n",
    "        print(f\"Ğ’Ñ–Ğ´Ğ³ÑƒĞº Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¹ ğŸ™‚ (Ğ¹Ğ¼Ğ¾Ğ²Ñ–Ñ€Ğ½Ñ–ÑÑ‚ÑŒ {prediction:.2f})\")\n",
    "    else:\n",
    "        print(f\"Ğ’Ñ–Ğ´Ğ³ÑƒĞº Ğ½ĞµĞ³Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¹ ğŸ™ (Ğ¹Ğ¼Ğ¾Ğ²Ñ–Ñ€Ğ½Ñ–ÑÑ‚ÑŒ {1-prediction:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5a87bd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
      "Ğ’Ñ–Ğ´Ğ³ÑƒĞº Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¹ ğŸ™‚ (Ğ¹Ğ¼Ğ¾Ğ²Ñ–Ñ€Ğ½Ñ–ÑÑ‚ÑŒ 0.86)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step\n",
      "Ğ’Ñ–Ğ´Ğ³ÑƒĞº Ğ¿Ğ¾Ğ·Ğ¸Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¹ ğŸ™‚ (Ğ¹Ğ¼Ğ¾Ğ²Ñ–Ñ€Ğ½Ñ–ÑÑ‚ÑŒ 0.74)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- 7. ĞŸĞµÑ€ĞµĞ²Ñ–Ñ€ĞºĞ° ---\n",
    "predict_review(\"the movie was very interesting, exciting\")\n",
    "predict_review(\"the film is not interesting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d14bba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8df1a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
